--------------------------------------------------------------------------------------------------------------------------------------------------
//175
--------------------------------------------------------------------------------------------------------------------------------------------------

val query = "(SELECT * FROM person_175) AS person"
val personDF = spark.read.jdbc(url, query, connectionProperties)

val query = "(SELECT * FROM address_175) AS address"
val addressDF = spark.read.jdbc(url, query, connectionProperties)

val joinCondition = personDF.col("personid") === addressDF.col("personid")
val joinedDF = personDF.join(addressDF,joinCondition,"inner")

joinedDF.show

--------------------------------------------------------------------------------------------------------------------------------------------------
//181
--------------------------------------------------------------------------------------------------------------------------------------------------

val query = "(SELECT * FROM employee_181) AS employee"

val employeeDF = spark.read.jdbc(url, query, connectionProperties)

val joinedDF = employeeDF.as("emp").join(employeeDF.as("mgr"),$"emp.manager_id"===$"mgr.id" && $"emp.salary" > $"mgr.salary","inner").select($"emp.name")

joinedDF.show

--------------------------------------------------------------------------------------------------------------------------------------------------
//182
--------------------------------------------------------------------------------------------------------------------------------------------------

val query = "(SELECT * FROM person_182) AS person"

val personDF = spark.read.jdbc(url, query, connectionProperties)

val duplicateDF = personDF.groupBy(col("email")).agg(count(col("id")).as("cnt")).where($"cnt">1).select(col("email"))

duplicateDF.show

--------------------------------------------------------------------------------------------------------------------------------------------------
//183
--------------------------------------------------------------------------------------------------------------------------------------------------

val query = "(SELECT * FROM customers_183) AS customers"

val customerDF = spark.read.jdbc(url, query, connectionProperties)

val query = "(SELECT * FROM orders_183) AS orders"

val orderDF = spark.read.jdbc(url, query, connectionProperties)

// Direct Method

val joinedDF = customerDF.as("c").join(orderDF.as("o"),$"c.id"===$"o.customer_id","left_anti").select($"c.name")

//Conventional Method

val joinedDF = customerDF.as("c").join(orderDF.as("o"),$"c.id"===$"o.customer_id","left_outer").where($"o.id".isNull).select($"c.name")

joinedDF.show

--------------------------------------------------------------------------------------------------------------------------------------------------
//196
--------------------------------------------------------------------------------------------------------------------------------------------------

import org.apache.spark.sql.expressions.Window

val query = "(SELECT * FROM person_196) AS person"

val personDF = spark.read.jdbc(url, query, connectionProperties)

val w = Window.partitionBy("email")

val distinctPersonDF = personDF.withColumn("min",min($"id").over(w)).where($"min"===$"id").drop($"min")

distinctPersonDF.show

--------------------------------------------------------------------------------------------------------------------------------------------------
//197
--------------------------------------------------------------------------------------------------------------------------------------------------


val query = "(SELECT * FROM weather_197) AS weather"

val weatherDF = spark.read.jdbc(url, query, connectionProperties)

val resultDF = weatherDF.as("w1")
		.join(weatherDF.as("w2"),$"w2.record_date"+1===$"w1.record_date" && $"w2.temperature"<$"w1.temperature","inner")
		.select($"w1.id")

resultDF.show

--------------------------------------------------------------------------------------------------------------------------------------------------
//511
--------------------------------------------------------------------------------------------------------------------------------------------------


val query = "(SELECT * FROM activity_511) AS activity"

val activityDF = spark.read.jdbc(url, query, connectionProperties)

val firstloginDF = activityDF
		.groupBy($"player_id")
		.agg(min($"event_date").as("first_login"))
		

firstloginDF.show

--------------------------------------------------------------------------------------------------------------------------------------------------
//512
--------------------------------------------------------------------------------------------------------------------------------------------------


val query = "(SELECT * FROM activity_511) AS activity"

val activityDF = spark.read.jdbc(url, query, connectionProperties)

val firstloginDF = activityDF
		.groupBy($"player_id")
		.agg(min($"event_date").as("first_login"))
		
val fisrtDeviceDF = activityDF.as("act")
			.join(firstloginDF.as("fl"),$"act.player_id"===$"fl.player_id" && $"act.event_date"===$"fl.first_login","inner")
			.select($"act.player_id",$"act.device_id")
			
fisrtDeviceDF.show

--------------------------------------------------------------------------------------------------------------------------------------------------
//577
--------------------------------------------------------------------------------------------------------------------------------------------------


val query = "(SELECT * FROM employee_577) AS employee"

val employeeDF = spark.read.jdbc(url, query, connectionProperties)

val query = "(SELECT * FROM bonus_577) AS bonus"

val bonusDF = spark.read.jdbc(url, query, connectionProperties)

val resultDF = employeeDF.as("emp")
		.join(bonusDF.as("bn"),$"emp.empId"===$"bn.empId","left_outer")
		.where($"bn.bonus".isNull || $"bn.bonus"<1000)
		.select($"emp.name",$"bn.bonus")
resultDF.show

--------------------------------------------------------------------------------------------------------------------------------------------------
//584
--------------------------------------------------------------------------------------------------------------------------------------------------


val query = "(SELECT * FROM customer_584) AS customer"

val customerDF = spark.read.jdbc(url, query, connectionProperties)

val resultDF = customerDF.where($"reference_id".isNull || $"reference_id" =!= 2).select($"name")

resultDF.show

--------------------------------------------------------------------------------------------------------------------------------------------------
//586
--------------------------------------------------------------------------------------------------------------------------------------------------


val query = "(SELECT * FROM orders_586) AS orders"

val ordersDF = spark.read.jdbc(url, query, connectionProperties)

val resultDF = ordersDF.groupBy($"customer_number").agg(count($"order_number").as("cnt")).orderBy(desc("cnt")).select($"customer_number").limit(1)

resultDF.show

--------------------------------------------------------------------------------------------------------------------------------------------------
//595
--------------------------------------------------------------------------------------------------------------------------------------------------


val query = "(SELECT * FROM world_595) AS world"

val worldDF = spark.read.jdbc(url, query, connectionProperties)

val resultDF = worldDF.where($"population" >= 25000000 || $"area" >= 3000000).select($"name",$"population",$"area")

resultDF.show
